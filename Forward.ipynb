{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 3, 129)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "import cmath\n",
    "import scipy.fftpack\n",
    "\n",
    "# To Ask, signal in frequency domain or time domain ? if Time how to transorm to frequency ? Is it fourier transform ? \n",
    "# I used Fourier Transform to use the signal\n",
    "\n",
    "# Should I rescale the points to have them in a unit circle ?\n",
    "# Does the rfftfreq give the frequencies used in the fourier transform rfft \n",
    "# The length of the array given by rfftfreq is (n/2) + 1, last week you used 128 samples as an example so should I use 254 to have 128 frequency samples or just use 128 in the rfftfreq function directly and have 65 frequency samples \n",
    "# What tests could I do to see if my forward model is right\n",
    "# How to read the lego thing \n",
    "\n",
    "def forward(sourceSignal, numberOfMicrophones, microphonesPosition, minDegree = 0, maxDegree = 360, step = 1):\n",
    "    \n",
    "    ''' Forward Model\n",
    " \n",
    "     Input:\n",
    "       - sourceSignal: Signal in a discrete form in the time domain as a numpy matrix (vector in reality)\n",
    "       - minDegree : the degree minimal in which we want to see the signal received (included)\n",
    "       - maxDegree : the degree maximal in which we want to see the signal received (excluded)\n",
    "       - step : the step we want between each direction\n",
    "       - numberOfMicrophones: number of microphones present in the model\n",
    "       - microphonesPosition: the positions of the microphones \n",
    "    \n",
    "     Output:\n",
    "       - y: signals received by the microphones in each degrees from minDegree to maxDegree by doing a step of step degrees\n",
    "    '''\n",
    "        \n",
    "    for i in range(minDegree, maxDegree, step):\n",
    "        if i == minDegree:\n",
    "            y = [forward_degree(sourceSignal, i, numberOfMicrophones, microphonesPosition)]\n",
    "        else:\n",
    "            y.append(forward_degree(sourceSignal, i, numberOfMicrophones, microphonesPosition))\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    return np.array(y)\n",
    "\n",
    "def forward_degree(sourceSignal, thetaSignal, numberOfMicrophones, microphonesPosition):\n",
    "    \n",
    "    ''' Forward Model\n",
    " \n",
    "     Input:\n",
    "       - sourceSignal: Signal in a discrete form in the time domain as a numpy matrix (vector in reality)\n",
    "       - thetaSignal: The direction  degree of the source (in degrees not radians)\n",
    "       - numberOfMicrophones: number of microphones present in the model\n",
    "       - microphonesPosition: the positions of the microphones \n",
    "    \n",
    "     Output:\n",
    "       - y: signals received by the microphones\n",
    "    '''\n",
    "    \n",
    "    micPosX = np.zeros(numberOfMicrophones)\n",
    "    micPosY = np.zeros(numberOfMicrophones)\n",
    "    \n",
    "    for i in range(numberOfMicrophones):\n",
    "        (micPosX[i], micPosY[i]) = microphonesPosition[i]\n",
    "    \n",
    "    # We calculate the distances between the source and the different microphones\n",
    "    # This is an hypothetic distance, as the micrphone is considered \"far away\", using the direction of the signal\n",
    "    \n",
    "    distanceSourceMicrophones = np.zeros(numberOfMicrophones)\n",
    "    \n",
    "    for i in range(numberOfMicrophones):\n",
    "        horizontalDistance = micPosX[i] - math.cos(math.radians(thetaSignal))\n",
    "        verticalDistance = micPosY[i] - math.sin(math.radians(thetaSignal))\n",
    "        distanceSourceMicrophones[i] = math.sqrt(math.pow(horizontalDistance, 2) + math.pow(verticalDistance, 2))\n",
    "            \n",
    "    \n",
    "    sample_rate = 8000 # The maximum frequency we want to use\n",
    "    sample_number = 256 # The number of points we will have\n",
    "    freq = np.fft.rfftfreq(sample_number, d=1./(2*sample_rate))\n",
    "    \n",
    "    sourceFourier = np.fft.rfft(sourceSignal, sample_number)\n",
    "    (sizeX, )  = sourceFourier.shape\n",
    "    \n",
    "    hFunction = np.zeros((numberOfMicrophones, sizeX), dtype=np.complex_)\n",
    "    c = 340.29 #speed of sound 340.29 m/s\n",
    "\n",
    "        \n",
    "    y = np.zeros((numberOfMicrophones, sizeX), dtype=np.complex_)\n",
    "\n",
    "    #The different filter signals use the distance : H(w) = exp(-j*w*tau)\n",
    "    for i in range(numberOfMicrophones):\n",
    "        tau = distanceSourceMicrophones[i] / c\n",
    "        for k in range(sizeX):\n",
    "            hFunction[i][k] = cmath.exp(-freq[k]*1j*tau)\n",
    "            y[i][k] = sourceFourier[k]*hFunction[i][k]\n",
    "\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "y = forward(np.array([1,5,6,8,2]), 3, [(1, 0.5), (0.8,0.33), (0.6,0.8)])\n",
    "y.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
