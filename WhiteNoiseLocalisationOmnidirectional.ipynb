{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Test 0, theta: [352.], theta_hat: [354.], err: 2.0\n",
      "1\n",
      "Test 1, theta: [190.], theta_hat: [358.], err: 168.0\n",
      "2\n",
      "Test 2, theta: [294.], theta_hat: [358.], err: 64.0\n",
      "3\n",
      "Test 3, theta: [320.], theta_hat: [358.], err: 38.0\n",
      "4\n",
      "Test 4, theta: [246.], theta_hat: [358.], err: 112.0\n",
      "5\n",
      "Test 5, theta: [150.], theta_hat: [358.], err: 152.0\n",
      "6\n",
      "Test 6, theta: [52.], theta_hat: [358.], err: 54.0\n",
      "7\n",
      "Test 7, theta: [86.], theta_hat: [358.], err: 88.0\n",
      "8\n",
      "Test 8, theta: [124.], theta_hat: [190.], err: 66.0\n",
      "9\n",
      "Test 9, theta: [232.], theta_hat: [358.], err: 126.0\n",
      "10\n",
      "Test 10, theta: [338.], theta_hat: [358.], err: 20.0\n",
      "11\n",
      "Test 11, theta: [306.], theta_hat: [358.], err: 52.0\n",
      "12\n",
      "Test 12, theta: [194.], theta_hat: [356.], err: 162.0\n",
      "13\n",
      "Test 13, theta: [152.], theta_hat: [352.], err: 160.0\n",
      "14\n",
      "Test 14, theta: [118.], theta_hat: [352.], err: 126.0\n",
      "15\n",
      "Test 15, theta: [156.], theta_hat: [358.], err: 158.0\n",
      "16\n",
      "Test 16, theta: [102.], theta_hat: [358.], err: 104.0\n",
      "17\n",
      "Test 17, theta: [78.], theta_hat: [358.], err: 80.0\n",
      "18\n",
      "Test 18, theta: [146.], theta_hat: [358.], err: 148.0\n",
      "19\n",
      "Test 19, theta: [80.], theta_hat: [358.], err: 82.0\n",
      "20\n",
      "Test 20, theta: [92.], theta_hat: [348.], err: 104.0\n",
      "21\n",
      "Test 21, theta: [194.], theta_hat: [358.], err: 164.0\n",
      "22\n",
      "Test 22, theta: [34.], theta_hat: [218.], err: 176.0\n",
      "23\n",
      "Test 23, theta: [126.], theta_hat: [46.], err: 80.0\n",
      "24\n",
      "Test 24, theta: [194.], theta_hat: [358.], err: 164.0\n",
      "25\n",
      "Test 25, theta: [118.], theta_hat: [358.], err: 120.0\n",
      "26\n",
      "Test 26, theta: [182.], theta_hat: [358.], err: 176.0\n",
      "27\n",
      "Test 27, theta: [116.], theta_hat: [358.], err: 118.0\n",
      "28\n",
      "Test 28, theta: [258.], theta_hat: [358.], err: 100.0\n",
      "29\n",
      "Test 29, theta: [88.], theta_hat: [358.], err: 90.0\n",
      "30\n",
      "Test 30, theta: [288.], theta_hat: [358.], err: 70.0\n",
      "31\n",
      "Test 31, theta: [182.], theta_hat: [358.], err: 176.0\n",
      "32\n",
      "Test 32, theta: [198.], theta_hat: [358.], err: 160.0\n",
      "33\n",
      "Test 33, theta: [272.], theta_hat: [358.], err: 86.0\n",
      "34\n",
      "Test 34, theta: [266.], theta_hat: [356.], err: 90.0\n",
      "35\n",
      "Test 35, theta: [230.], theta_hat: [356.], err: 126.0\n",
      "36\n",
      "Test 36, theta: [136.], theta_hat: [358.], err: 138.0\n",
      "37\n",
      "Test 37, theta: [176.], theta_hat: [358.], err: 178.0\n",
      "38\n",
      "Test 38, theta: [218.], theta_hat: [358.], err: 140.0\n",
      "39\n",
      "Test 39, theta: [294.], theta_hat: [358.], err: 64.0\n",
      "40\n",
      "Test 40, theta: [66.], theta_hat: [358.], err: 68.0\n",
      "41\n",
      "Test 41, theta: [222.], theta_hat: [326.], err: 104.0\n",
      "42\n",
      "Test 42, theta: [22.], theta_hat: [358.], err: 24.0\n",
      "43\n",
      "Test 43, theta: [270.], theta_hat: [358.], err: 88.0\n",
      "44\n",
      "Test 44, theta: [220.], theta_hat: [358.], err: 138.0\n",
      "45\n",
      "Test 45, theta: [150.], theta_hat: [358.], err: 152.0\n",
      "46\n",
      "Test 46, theta: [94.], theta_hat: [358.], err: 96.0\n",
      "47\n",
      "Test 47, theta: [212.], theta_hat: [358.], err: 146.0\n",
      "48\n",
      "Test 48, theta: [38.], theta_hat: [358.], err: 40.0\n",
      "49\n",
      "Test 49, theta: [128.], theta_hat: [358.], err: 130.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.],\n",
       "       [ 84.],\n",
       "       [ 32.],\n",
       "       [ 19.],\n",
       "       [ 56.],\n",
       "       [104.],\n",
       "       [153.],\n",
       "       [136.],\n",
       "       [ 33.],\n",
       "       [ 63.],\n",
       "       [ 10.],\n",
       "       [ 26.],\n",
       "       [ 81.],\n",
       "       [100.],\n",
       "       [117.],\n",
       "       [101.],\n",
       "       [128.],\n",
       "       [140.],\n",
       "       [106.],\n",
       "       [139.],\n",
       "       [128.],\n",
       "       [ 82.],\n",
       "       [ 92.],\n",
       "       [ 40.],\n",
       "       [ 82.],\n",
       "       [120.],\n",
       "       [ 88.],\n",
       "       [121.],\n",
       "       [ 50.],\n",
       "       [135.],\n",
       "       [ 35.],\n",
       "       [ 88.],\n",
       "       [ 80.],\n",
       "       [ 43.],\n",
       "       [ 45.],\n",
       "       [ 63.],\n",
       "       [111.],\n",
       "       [ 91.],\n",
       "       [ 70.],\n",
       "       [ 32.],\n",
       "       [146.],\n",
       "       [ 52.],\n",
       "       [168.],\n",
       "       [ 44.],\n",
       "       [ 69.],\n",
       "       [104.],\n",
       "       [132.],\n",
       "       [ 73.],\n",
       "       [160.],\n",
       "       [115.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import math \n",
    "import scipy\n",
    "import scipy.signal\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from google.protobuf import text_format\n",
    "\n",
    "import itertools\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font_scale=1.5) \n",
    "cmap = \"PuBu\"\n",
    "\n",
    "# MAYBE TO CHANGE add same noise everywehre\n",
    "\n",
    "def whiteNoise(numberOfSources, starting_frequency = 0):\n",
    "    ''' White noise localization \n",
    "    \n",
    "     Input:\n",
    "       - \n",
    "       - \n",
    "       - \n",
    "       - \n",
    "    \n",
    "     Output:\n",
    "       - \n",
    "    '''\n",
    "    n_samples = 128\n",
    "    values = [numberOfSources, n_samples]\n",
    "\n",
    "    outpath = os.path.join('StackingOmni',  '{0}source{1}samples'.format(*values))\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    logfile = os.path.join(outpath, \"log.txt\")\n",
    "\n",
    "    logging.basicConfig(filename=logfile, format='%(asctime)s %(message)s', level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    f0 = starting_frequency #starting frequency index\n",
    "    step = 1 #discretization (for now we want to use the 180 angles so we keep it like that)\n",
    "    # maybe to add - starting frequency (f0)\n",
    "    Fn = n_samples/2. +  1 #number of frequencies in spectrogram \n",
    "    # noise in dB\n",
    "    SNR = 20\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Generation H_theta omnidirectional (instead of load)\n",
    "    '''\n",
    "\n",
    "    # Decided by me. Should it be random ? or special ones ? \n",
    "    # If we want less mics put less positions\n",
    "    mic_positions = np.array([(1,0), (0,1), (0,0), (-1,0), (0,-1), (0.3, 0.3)])\n",
    "\n",
    "    number_mics = mic_positions.shape[0]\n",
    "    N = number_mics\n",
    "\n",
    "\n",
    "    # We want a discretization of every 2 degrees\n",
    "    step_angle = 2\n",
    "    number_angles = int(360/step_angle)\n",
    "    # the different frequencies\n",
    "    c = 340.29 #speed of sound 340.29 m/s\n",
    "    sample_rate = 8000 # The maximum frequency we want to use\n",
    "    freq = np.fft.rfftfreq(n_samples, d=1./(2*sample_rate))\n",
    "    number_frequencies = int(n_samples/2 + 1)\n",
    "\n",
    "\n",
    "    H_theta_freq_total = np.zeros((number_mics, number_angles, number_frequencies), dtype=complex)\n",
    "\n",
    "\n",
    "    for index_H in range(number_angles):\n",
    "        thetaAngle = step_angle*index_H\n",
    "        # We calculate the distances between the source and the different microphones\n",
    "        # This is an hypothetic distance, as the micrphone is considered \"far away\", using the direction of the signal\n",
    "\n",
    "        horizontalDistance = mic_positions[:,0] - math.cos(math.radians(thetaAngle))\n",
    "        verticalDistance = mic_positions[:,1] - math.sin(math.radians(thetaAngle))\n",
    "        distanceSourceMicrophones = np.sqrt(np.power(horizontalDistance, 2) + np.power(verticalDistance, 2))\n",
    "\n",
    "        tau = distanceSourceMicrophones/c\n",
    "\n",
    "        tau_reshaped = np.transpose(np.array([tau,]*freq.shape[0]))\n",
    "        freq_reshaped = np.array([freq,]*tau.shape[0])\n",
    "\n",
    "        H_theta_freq_total[:,index_H,:] = np.exp(-freq_reshaped*1j*tau_reshaped)\n",
    "\n",
    "    number_angles = H_theta_freq_total.shape[1]\n",
    "    number_mics = H_theta_freq_total.shape[0]\n",
    "\n",
    "    # time \n",
    "    theta_transition = np.transpose(H_theta_freq_total)\n",
    "    H_theta_time_total = np.zeros((n_samples, number_angles, number_mics))\n",
    "    for n_mic in range(number_mics):\n",
    "        H_theta_time_total[:,:,n_mic] = np.transpose(np.fft.irfft(np.transpose(theta_transition[:,:,n_mic]), n_samples))\n",
    "            \n",
    "    # freq stacked\n",
    "    H_theta_freq_stacked = H_theta_freq_total[0,:,:]\n",
    "    for n_mic in range(1, number_mics):\n",
    "        H_theta_freq_stacked = np.append(H_theta_freq_stacked, H_theta_freq_total[n_mic,:,:], axis=1)\n",
    "\n",
    "    '''\n",
    "    End Generation H_theta omnidirectional\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    dev = 'Omnidirectional' # Change if using Kemar or lego\n",
    "    logger.info('Load transfer functions %s'%dev)\n",
    "    '''\n",
    "    H_theta_time_total = np.load('kemar_h_theta_1deg_time.npy')    \n",
    "    \n",
    "    print(H_theta_time_total.shape)\n",
    "    '''\n",
    "    Df = H_theta_time_total[:, ::step, 0].shape[1] #number of directions for a fine discretization\n",
    "            \n",
    "    anglesf = np.arange(Df, dtype=np.int64)*360./Df # list of angles in degrees\n",
    "\n",
    "        \n",
    "    number_microphones = H_theta_time_total.shape[2]\n",
    "        \n",
    "    #coarse discretization,  model, no need of the ::step because already done in time \n",
    "    H_theta_freq_stacked = np.transpose(H_theta_freq_stacked)\n",
    "    [F, D] = H_theta_freq_stacked.shape \n",
    "    #F: number of frequencies,  D: number of directions\n",
    "    \n",
    "    #length of the convolution might have to adapt something\n",
    "    obs_len = n_samples + H_theta_time_total[:,:,0].shape[0] - 1\n",
    "        \n",
    "    numAngles = H_theta_time_total.shape[1]\n",
    "    runs = 50\n",
    "    J = numberOfSources\n",
    "    conf_matrix = np.zeros((numAngles, numAngles)) #confusion  matrix\n",
    "    \n",
    "    #TO ADAPT for the runs value and maybe microphones value\n",
    "    err_per_source = np.zeros((runs, J))\n",
    "    min_err_per_source = np.zeros((runs, J))\n",
    "    \n",
    "    logger.info('Number of runs %s'%(runs))\n",
    "    logger.info('Noise in decibel %s'%(SNR))\n",
    "    logger.info('Number of sources %s'%(J))\n",
    "    logger.info('Number of samples %s'%(n_samples))    \n",
    "    #To keep the minimal error between each source at each run \n",
    "    min_err_by_run = np.zeros(runs)\n",
    "\n",
    "    for rns in range(runs):\n",
    "        print(rns)\n",
    "        #choose the directions randomly on the fine grid\n",
    "        theta = np.random.choice(range(Df), numberOfSources, replace=False)\n",
    "        Source_signal = np.zeros((n_samples, J)) #list of source signals\n",
    "        for j in range(J):\n",
    "            Source_signal[:, j] = np.random.randn(n_samples) #source in time: random gaussian signal \n",
    "        # First Mic \n",
    "        \n",
    "        #recorded time domain signal\n",
    "        yt = np.zeros((obs_len, )) \n",
    "\n",
    "        for j in range(J):\n",
    "            #source signal convolved with corresponding directional response\n",
    "            first_H_theta =H_theta_time_total[:,:,0]\n",
    "            yt += np.convolve(Source_signal[:, j], first_H_theta[:, theta[j]]) \n",
    "\n",
    "        # Generate noise at required SNR    \n",
    "        sig_norm = np.linalg.norm(yt)\n",
    "        noise_t = np.random.randn(obs_len, ) #additive gaussian noise\n",
    "        noise_norm = sig_norm/(10.**(SNR/20.))\n",
    "        noise_t = noise_norm*noise_t/np.linalg.norm(noise_t)\n",
    "\n",
    "        yt += noise_t #noisy signal\n",
    "\n",
    "        (freq_samples, seg_times, y) = scipy.signal.stft(yt, Fn, nperseg=n_samples)\n",
    "        #print(y)\n",
    "        #Other Mics \n",
    "        \n",
    "        for i in range(1, number_microphones):\n",
    "            #recorded time domain signal\n",
    "            yt = np.zeros((obs_len, )) \n",
    "\n",
    "            for j in range(J):\n",
    "                #source signal convolved with corresponding directional response\n",
    "                first_H_theta =H_theta_time_total[:,:,i]\n",
    "                yt += np.convolve(Source_signal[:, j], first_H_theta[:, theta[j]]) \n",
    "\n",
    "            # Generate noise at required SNR    \n",
    "            sig_norm = np.linalg.norm(yt)\n",
    "            noise_t = np.random.randn(obs_len, ) #additive gaussian noise\n",
    "            noise_norm = sig_norm/(10.**(SNR/20.))\n",
    "            noise_t = noise_norm*noise_t/np.linalg.norm(noise_t)\n",
    "\n",
    "            yt += noise_t #noisy signal\n",
    "\n",
    "            (freq_samples, seg_times, toAdd) = scipy.signal.stft(yt, Fn, nperseg=n_samples)\n",
    "            y = np.append(y,toAdd,axis=0)\n",
    "        #print(\"NEW Y\")\n",
    "        #print(y.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        y_mean = np.mean(np.abs(y)**2, axis=1) #mean power frame\n",
    "        y_mean = y_mean/np.linalg.norm(y_mean) #normalize the observation\n",
    "\n",
    "        # Exhaustive search algorithm\n",
    "\n",
    "        # Initialize variables\n",
    "        best_ind = np.inf #index corresponding to best direction tuple\n",
    "        smallest_norm = np.inf #smallest projection error\n",
    "        best_dir = theta #best direction tuple\n",
    "\n",
    "        # Search all combinations\n",
    "        pairs2 = combinations(range(D), J)\n",
    "        for q2, d2 in enumerate(pairs2): \n",
    "            Bj = np.abs(H_theta_freq_stacked[:, d2])**2 #vectors in current guess\n",
    "            Pj = Bj.dot(np.linalg.pinv(Bj)) #projection matrix\n",
    "\n",
    "            proj_error = np.linalg.norm((np.eye(F) - Pj).dot(y_mean)) #projection error\n",
    "\n",
    "            if proj_error <= smallest_norm:\n",
    "                smallest_norm = proj_error\n",
    "                best_ind = q2\n",
    "                best_dir = d2\n",
    "        theta_hat = step*np.array(best_dir) #map coarse index to fine index\n",
    "        #print(theta)\n",
    "        #print(theta_hat)\n",
    "        min_err, best_perm = calculate_angle_error(theta, theta_hat, anglesf) #calculate error between chosen and true directions\n",
    "        conf_matrix[theta, best_perm] += 1\n",
    "        \n",
    "        min_err_by_run[rns] = min_err\n",
    "\n",
    "        for src_j in range(J): #error per source\n",
    "            err_per_source[rns, src_j] = np.sum(np.absolute(((best_perm[src_j]-theta[src_j]+180) % 360)-180))\n",
    "            \n",
    "        print('Test %s, theta: %s, theta_hat: %s, err: %s'%(rns, anglesf[theta], anglesf[best_perm], min_err))\n",
    "        logger.info('Test %s, theta: %s, theta_hat: %s, err: %s'%(rns, anglesf[theta], anglesf[best_perm], min_err))\n",
    "    logger.info('Err_per_source average: %s, median: %s, Min_err average: %s, median: %s'%(np.mean(err_per_source, axis=0), np.median(err_per_source, axis=0), np.mean(min_err_by_run, axis=0), np.median(min_err_by_run, axis=0)))\n",
    "    logger.info('Err_per_source max: %s, min: %s, Min_err max: %s, min: %s'%(np.max(err_per_source, axis=0), np.min(err_per_source, axis=0), np.max(min_err_by_run, axis=0), np.min(min_err_by_run, axis=0)))\n",
    "    hm = sns.heatmap(20*np.log10(conf_matrix+1e-80), cmap=cmap, xticklabels=False,  yticklabels=False)\n",
    "    plt.xlabel('Estimate')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(os.path.join(outpath, 'conf_matrix_{0}source{1}samples.png'.format(*values)))\n",
    "    return err_per_source\n",
    "\n",
    "# Taken from https://github.com/swing-research/scatsense/blob/master/core/signal.py \n",
    "# Code written by Dalia El Badawy\n",
    "def calculate_angle_error(theta,theta_hat,angles):\n",
    "    '''Average localization error in degrees (modulo 360)\n",
    "    Also finds the best permutation that gives the lowest error\n",
    "    Input:\n",
    "        theta: array of true indices\n",
    "        theta_hat: array of estimated indices\n",
    "        angles: list of angles in degrees\n",
    "    '''\n",
    "    J = len(theta) #number of sources\n",
    "    all_perms = itertools.permutations(theta_hat) #all permutations\n",
    "    min_err = np.Inf\n",
    "\n",
    "    for beta in all_perms:\n",
    "        curr_err = np.sum(np.absolute(((angles[np.array(beta)]-angles[theta]+180) % 360)-180))*1./J;\n",
    "        if curr_err<min_err:\n",
    "            min_err = curr_err\n",
    "            perm = np.array(beta)\n",
    "            \n",
    "    return min_err,perm\n",
    "\n",
    "\n",
    "whiteNoise(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
