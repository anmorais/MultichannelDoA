{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 180)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  3.],\n",
       "       [  2.],\n",
       "       [ 31.],\n",
       "       [  1.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  2.],\n",
       "       [  0.],\n",
       "       [  7.],\n",
       "       [  0.],\n",
       "       [ 36.],\n",
       "       [  2.],\n",
       "       [  1.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [178.],\n",
       "       [  1.],\n",
       "       [  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "import scipy\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from google.protobuf import text_format\n",
    "\n",
    "import itertools\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "def whiteNoise(numberOfSources, starting_frequency = 0):\n",
    "    ''' White noise localization \n",
    "    \n",
    "     Input:\n",
    "       - \n",
    "       - \n",
    "       - \n",
    "       - \n",
    "    \n",
    "     Output:\n",
    "       - \n",
    "    '''\n",
    "    outpath = os.path.join('output',  '{:%Y%m%d_%H%M}'.format(datetime.datetime.now()))\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    logfile = os.path.join(outpath, \"log.txt\")\n",
    "\n",
    "    logging.basicConfig(filename=logfile, format='%(asctime)s %(message)s', level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    f0 = starting_frequency #starting frequency index\n",
    "    step = 1 #discretization (for now we want to use the 180 angles so we keep it like that)\n",
    "    m = 1 #index of used microphone (only used when H_theta0_t = H_theta_total[:, :, m])\n",
    "    n_samples = 128\n",
    "\n",
    "    dev = 'lego' # Change if using Kemar or lego\n",
    "    logger.info('Load transfer functions %s'%dev)\n",
    "    \n",
    "    H_theta_total = np.load('lego1_h_theta_time.npy')\n",
    "\n",
    "   # H_theta_stacked = H_theta_total[:, :, 0]\n",
    "    \n",
    "    #for i in range(1, H_theta_total.shape[2]):\n",
    "     #   H_theta_stacked = np.append(H_theta_stacked, H_theta_total[:, :, i],axis = 0)\n",
    "        \n",
    "    \n",
    "        \n",
    "    H_theta0_t = H_theta_total[:, :, m] # For one mic\n",
    "    #H_theta0_t = H_theta_stacked\n",
    "    \n",
    "    H_theta_t = H_theta0_t[:, ::step] #coarse discretization\n",
    "    Df = H_theta_t.shape[1] #number of directions for a fine discretization\n",
    "\n",
    "#    First_H_theta = H_theta_total[:, :, 0]\n",
    " #   First_H_theta_transpose = np.transpose(First_H_theta)\n",
    "  #  First_H_theta_freq = np.fft.rfft(First_H_theta_transpose, n_samples)\n",
    "   # H_theta_freq_stacked = np.transpose(First_H_theta_freq)\n",
    "    \n",
    "#    for j in range(1, H_theta_total.shape[2]):\n",
    " #       Transpose_of_time = np.transpose(H_theta_total[:, :, j])    \n",
    "  #      Freq_One_mic = np.fft.rfft(Transpose_of_time, n_samples) #load transfer functions (includes 4 microphones)\n",
    "   #     Freq_One_mic = np.transpose(Freq_One_mic)\n",
    "    #    H_theta_freq_stacked = np.append(H_theta_freq_stacked, Freq_One_mic,axis = 0)\n",
    "\n",
    "\n",
    "  #  H_theta0 = H_theta_freq_stacked\n",
    "    \n",
    "    H_theta_t_transpose = np.transpose(H_theta_t)    \n",
    "    H_theta0 = np.fft.rfft(H_theta_t_transpose, n_samples) \n",
    "    H_theta0 = np.transpose(H_theta0)\n",
    "    \n",
    "    anglesf = np.arange(Df, dtype=np.int64)*360./Df # list of angles in degrees\n",
    "    \n",
    "    theta = np.random.choice(range(Df), numberOfSources, replace=False) #choose the directions randomly on the fine grid   \n",
    "        \n",
    "    H_theta = H_theta0[f0:, ::step] #coarse discretization,  model\n",
    "    [F, D] = H_theta.shape #F: number of frequencies,  D: number of directions\n",
    "    #print(F)\n",
    "    \n",
    "    runs = 20\n",
    "    #n_samples = H_theta_total.shape[2]*n_samples\n",
    "    J = numberOfSources\n",
    "    conf_matrix = np.zeros((360, 360)) #confusion  matrix\n",
    "    err_per_source = np.zeros((runs, J))\n",
    "    min_err_per_source = np.zeros((runs, J))\n",
    "    obs_len = n_samples + H_theta_t.shape[0] - 1#length of the convolution\n",
    "    SNR = 0 # noise of 20 dB\n",
    "    Fn = n_samples/2. + 1# H_theta_total.shape[2] #number of frequencies in spectrogram \n",
    "    \n",
    "    logger.info('Number of sources %s'%(J))\n",
    "    \n",
    "    for rns in range(runs):\n",
    "        St_all = np.zeros((n_samples, J)) #list of source signals\n",
    "        for j in range(J):\n",
    "            St_all[:, j] = np.random.randn(n_samples) #source in time: random gaussian signal \n",
    "\n",
    "        theta = np.random.choice(range(Df), J, replace=False) #choose the directions randomly on the fine grid  \n",
    "\n",
    "        yt = np.zeros((obs_len, )) #recorded time domain signal\n",
    "        #print(yt.shape)\n",
    "\n",
    "        for j in range(J):\n",
    "            yt += np.convolve(St_all[:, j], H_theta0_t[:, theta[j]]) #source signal convolved with corresponding directional response\n",
    "\n",
    "        # Generate noise at required SNR    \n",
    "        sig_norm = np.linalg.norm(yt)\n",
    "        noise_t = np.random.randn(obs_len, ) #additive gaussian noise\n",
    "        noise_norm = sig_norm/(10.**(SNR/20.))\n",
    "        noise_t = noise_norm*noise_t/np.linalg.norm(noise_t)\n",
    "\n",
    "        #yt += noise_t #noisy signal\n",
    "        \n",
    "\n",
    "\n",
    "        y = stft(yt, Fn)[f0:, :] #spectrogram of recorded signal\n",
    "        N = y.shape[1] #number of frames\n",
    "\n",
    "        y_mean = np.mean(np.abs(y)**2, axis=1) #mean power frame\n",
    "        y_mean = y_mean/np.linalg.norm(y_mean) #normalize the observation\n",
    "        #print(y_mean.shape)\n",
    "\n",
    "        # Exhaustive search algorithm\n",
    "\n",
    "        # Initialize variables\n",
    "        best_ind = np.inf #index corresponding to best direction tuple\n",
    "        smallest_norm = np.inf #smallest projection error\n",
    "        best_dir = theta #best direction tuple\n",
    "\n",
    "        # Search all combinations\n",
    "        pairs2 = combinations(range(D), J)\n",
    "        for q2, d2 in enumerate(pairs2): \n",
    "            Bj = np.abs(H_theta[:, d2])**2 #vectors in current guess\n",
    "            #print(Bj.shape)\n",
    "            Pj = Bj.dot(np.linalg.pinv(Bj)) #projection matrix\n",
    "            #print(Pj.shape)\n",
    "            \n",
    "            proj_error = np.linalg.norm((np.eye(F) - Pj).dot(y_mean)) #projection error\n",
    "\n",
    "            if proj_error <= smallest_norm:\n",
    "                smallest_norm = proj_error\n",
    "                best_ind = q2\n",
    "                best_dir = d2\n",
    "        theta_hat = step*np.array(best_dir) #map coarse index to fine index\n",
    "        min_err, best_perm = calculate_angle_error(theta, theta_hat, anglesf) #calculate error between chosen and true directions\n",
    "        conf_matrix[theta, best_perm] += 1\n",
    "        \n",
    "        for src_j in range(J): #error per source\n",
    "            err_per_source[rns, src_j] = np.sum(np.absolute(((best_perm[src_j]-theta[src_j]+180) % 360)-180));\n",
    "            #min_err_per_source[rns, src_j] = min_err\n",
    "        \n",
    "        logger.info('Test %s, theta: %s, theta_hat: %s, err: %s'%(rns, anglesf[theta], anglesf[best_perm], min_err))\n",
    "    \n",
    "    #print(min_err_per_source)\n",
    "    \n",
    "    return err_per_source\n",
    "\n",
    "\n",
    "# Taken from https://github.com/swing-research/scatsense/blob/master/core/signal.py\n",
    "# Code written by Dalia El Badawy\n",
    "def stft(x,F):\n",
    "    '''Compute STFT of 1D real signal x\n",
    "    F: number of frequencies\n",
    "    '''\n",
    "    wn = 2*(F-1) #window size in samples\n",
    "    nhop = int(wn/2) #hop size, 50% overlap\n",
    "    \n",
    "    L = len(x) #length of input signal\n",
    "    zero_pad = nhop #number of zeros to add before and after the signal\n",
    "    rem = int(L%nhop) #number of samples leftover\n",
    "    \n",
    "    if rem>0: # adjust zero padding to have an integer number of windows\n",
    "        zero_pad = int(wn-rem)#nhop-rem#wn-rem\n",
    "    x = np.hstack((np.zeros((nhop,)),x,np.zeros((zero_pad,)))) #zero padding at the beginning to avoid boundary effects\n",
    "    L = len(x) #new length of signal\n",
    "    \n",
    "    N = int((L-wn)/nhop + 1) #total number of frames\n",
    "    X = np.zeros((int(F),N),dtype=np.complex128) #output STFT matrix\n",
    "     \n",
    "   \n",
    "    w = 0.5- 0.5*np.cos(2*np.pi*np.arange(wn)/(wn)) #Hann window\n",
    "    for i in range(N): #compute windowed fft for every frame\n",
    "        xf = np.fft.rfft(x[int(i*nhop):int(i*nhop+wn)]*w)\n",
    "        X[:,i] = xf\n",
    "\n",
    "    return X \n",
    "\n",
    "# Taken from https://github.com/swing-research/scatsense/blob/master/core/signal.py \n",
    "# Code written by Dalia El Badawy\n",
    "def calculate_angle_error(theta,theta_hat,angles):\n",
    "    '''Average localization error in degrees (modulo 360)\n",
    "    Also finds the best permutation that gives the lowest error\n",
    "    Input:\n",
    "        theta: array of true indices\n",
    "        theta_hat: array of estimated indices\n",
    "        angles: list of angles in degrees\n",
    "    '''\n",
    "    J = len(theta) #number of sources\n",
    "    all_perms = itertools.permutations(theta_hat) #all permutations\n",
    "    min_err = np.Inf\n",
    "\n",
    "    for beta in all_perms:\n",
    "        curr_err = np.sum(np.absolute(((angles[np.array(beta)]-angles[theta]+180) % 360)-180))*1./J;\n",
    "        if curr_err<min_err:\n",
    "            min_err = curr_err\n",
    "            perm = np.array(beta)\n",
    "            \n",
    "    return min_err,perm\n",
    "\n",
    "whiteNoise(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
